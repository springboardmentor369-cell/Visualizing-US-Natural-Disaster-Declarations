## ğŸ“˜ Learning Journey as a Beginner
As a beginner in data analytics, this project represents my first structured hands-on experience with data cleaning, analysis, and visualization. Working with tools like Power BI, Power Query, Python, APIs, and live data sources was initially challenging, especially dealing with unfamilia words and tools ,handling large raw data, managing missing values and correcting data types

Over four weeks, I progressed through each stage of the data analytics lifecycleâ€”from basic data cleaning to exploratory data analysis and finally working with APIs and data pipelines. This documentation captures both what I learned and how my confidence grew while applying industry-relevant tools to a real-world dataset.
### ğŸ“… Week 1: Project Introduction & Basic Data Cleaning
#### ğŸ” Overview
* Gained a foundational understanding of the project objectives and dataset structure.
* Learned the importance of data cleaning as the first step in any data analytics project.
#### ğŸ§¹ Tools Introduced
* Power BI
* Power Query Editor
* Python (Basics)
#### ğŸªœ Key Learning & Steps
* Imported raw data into Power BI
* Reviewed dataset structure and column relevance
* Removed unnecessary and empty columns
* Filtered invalid and missing records
* Cleaned text fields using Replace Values
* Corrected data types (date, time, numeric)
* Performed basic cleaning using Python for comparison
#### ğŸ¯ Outcome
* Developed a clear understanding of structured vs unstructured data
* Prepared a clean, analysis-ready dataset
### ğŸ“… Week 2: Advanced Data Cleaning Using Python
#### ğŸ” Overview
* Focused on in-depth data cleaning and transformation using Python.
* Learned how Python enables automation and scalability in data preprocessing.
####  ğŸ›  Tools & Libraries
* Python
* Pandas
* NumPy
#### ğŸªœ Key Learning & Steps
* Loaded datasets using Pandas
* Identified missing values and duplicates
* Handled null values using imputation and filtering
* Standardized categorical data
* Removed outliers and inconsistent records
* Renamed and reformatted columns
* Validated data quality through checks
#### ğŸ¯ Outcome
* Built confidence in handling large datasets
* Learned reproducible and reusable data-cleaning workflows
### ğŸ“… Week 3: Exploratory Data Analysis (EDA) & API Fundamentals
#### ğŸ” Overview
* Explored data patterns and relationships using EDA techniques.
* Learned how APIs provide structured access to live and external data sources.
#### ğŸ›  Tools & Concepts
* Python
* EDA Techniques
* APIs
#### ğŸªœ Key Learning & Steps
* Understood API concepts (endpoint, request, response)
* Explored real-time data concept
* steps in performing EDA 
#### ğŸ¯ Outcome
* Gained insights into data behavior
* Understood how external data can enhance analysis
### ğŸ“… Week 4: Data Pipelines, Live Data & Advanced Sources
#### ğŸ” Overview
* Learned the concept APL pipelines.
* Explored real-time, synthetic, and customer-support data sources.
#### ğŸ›  Tools & Technologies
* APIs
* Web Scraping
* Live Data Sources
* Zendesk
* Python
#### ğŸªœ Key Learning & Steps
* concepts of dummy and synthetic data for testing
* Explored Zendesk data for support analytics
* Compared static vs live data sources
* Challenges of using live data 
#### ğŸ“Œ Why These Data Sources Matter

* Live data: Enables real-time decision-making

* Synthetic/Dummy data: Useful for testing without privacy risks

* Web scraping: Accesses data when APIs are unavailable

* Zendesk: Provides customer interaction insights

#### ğŸ¯ Outcome
* Learned scalable data engineering concepts
* Understood real-world data acquisition challenges and solutions
### ğŸŒŸ Overall Learning Outcome
* Gained hands-on experience in data cleaning and preprocessing using both Power BI and Python
* Learned to work with real-world datasets and handle missing values, inconsistencies, and unstructured data
* Improved proficiency in Exploratory Data Analysis (EDA) to identify patterns, trends, and anomalies
* Understood how APIs function, including making requests, handling responses, and transforming JSON data
* Built foundational knowledge of data pipelines and automated data workflows
* Learned the difference between static, live, dummy, and synthetic data, and when each is appropriate
* Gained exposure to web scraping techniques when APIs are unavailable
* Developed an understanding of customer support data through tools like Zendesk.
* Improved problem-solving skills through debugging, data validation, and iterative improvements
* Strengthened confidence in using industry-relevant tools and technologies
### ğŸ›  Tools Used Throughout the Project
* Power BI
* Power Query Editor
* Python
* Pandas & NumPy
* APIs
* Web Scraping
### ğŸ“… Week 5 :Data Modeling & Star Schema Design
#### ğŸ¯ Focus:
Building a proper data model and establishing relationships.
#### âœ… Key Activities:
* Imported landslide dataset into Power BI.
* Cleaned data types (converted text to numeric where required).
* Handled missing values (replaced "Unknown" with null).
* Designed Star Schema model:
   * Created Fact Table (Global_Landslide_Catalog).
   * Created Dimension tables (Country, Date, Category, etc.).
   * Established One-to-Many relationships.
   * Understood why Many-to-Many relationships cause ambiguity.

#### ğŸ§  Key Learning:
* Importance of Star Schema for performance and scalability.
* Difference between Fact and Dimension tables.
* How filter context flows in relationships.
* Why numeric columns must not contain text values.
### ğŸ“… Week 6 :DAX Measures & Composite Measures
#### ğŸ¯ Focus:
Creating business metrics using DAX.
#### âœ… Key Measures Created:
* Total Events
* Total Fatalities
* Total Injuries
* Average Distance
* Total Impact
#### ğŸ”¥ Composite Measures:
* Fatality Rate per Event
* Impact Severity Index
* Distance per Event
#### ğŸ§  Key Learning:
* Difference between Measures vs Calculated Columns.
* Understanding Filter Context vs Row Context.
* Use of DIVIDE() instead of / to avoid errors.
* Creating meaningful KPIs from raw numbers.
### ğŸ“… Week 7 â€“ Visualization & Dashboard Creation

#### ğŸ¯ Learning Objectives
- Understanding different Power BI visualizations
- Learning dashboard layout design principles
- Creating interactive reports using slicers
- Building KPI cards and summary metrics

---

#### ğŸ“Š Topics Covered

##### ğŸ”¹ Data Visualization
- Bar Charts
- Line Charts
- Map Visualizations
- KPI Cards
- Slicers and Filters

##### ğŸ”¹ Dashboard Design Principles
- Visual hierarchy
- Proper spacing and alignment
- Consistent color theme
- Minimal and clean layout

---

#### ğŸ› ï¸ Practical Implementation

- Imported cleaned dataset into Power BI.
- Created calculated measures using DAX.
- Designed KPI section (Total Events, Fatalities, Fatalities per Event).
- Added slicers for country, year, and risk zone filtering.
- Structured the dashboard for better storytelling.

---

#### ğŸ“ˆ Outcome

Successfully developed an interactive dashboard that:
- Analyzes disaster trends.
- Identifies high-risk regions.
- Highlights key performance indicators.
- Enables dynamic filtering and analysis.

---

#### ğŸ’¡ Key Takeaways

- Effective visualization improves data storytelling.
- Proper alignment and formatting enhance professionalism.
- KPIs help summarize complex datasets clearly.
#### âœ¨ This documentation reflects my hands-on learning experience and practical exposure to modern data analytics techniques.
